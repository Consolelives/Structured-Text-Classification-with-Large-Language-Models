{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eea95b1-da03-4a58-9c58-e9a8b37526e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bbc import BBC\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "edaec20d-ceaf-4dcd-af34-f2553b5a2975",
   "metadata": {},
   "source": [
    "system_content = \"\"\"\n",
    "You are an AI assistant designed to analyze text data and classify it according to specific categories related to business, sports, and entertainment.  \n",
    "Your role is to extract structured information that helps categorize the content quickly and accurately.\n",
    "\n",
    "Business Context:  \n",
    "- Texts may include news, reports, or summaries involving various subcategories within business, sports, and entertainment.  \n",
    "- You will identify key named entities such as media personalities and their roles or jobs, which may not be limited to a fixed predefined list.  \n",
    "- Your classification must include confidence scores to indicate reliability.\n",
    "\n",
    "Your tasks for each input text are to:  \n",
    "1. Assign the most relevant categories in business, sports, and entertainment (if applicable).  \n",
    "2. Extract named entities with their full names and job descriptions (job can be free text, not limited to a fixed list).  \n",
    "3. Summarize any events mentioned strictly for those occurring in April.  Dont return any other month. If you are not sure, do not return false info.\n",
    "4. Provide a confidence score between 0 and 1 for your classification accuracy.\n",
    "\n",
    "Important notes:  \n",
    "- Use free-text for the job type of named entities, allowing for flexibility in new or uncommon job titles.  \n",
    "- Base your analysis solely on the provided text without assumptions.  \n",
    "- If unsure, lower the confidence score accordingly.  \n",
    "- The output should be structured and formatted as JSON matching the following keys:  \n",
    "  - business  \n",
    "  - sports  \n",
    "  - entertainment  \n",
    "  - confidence  \n",
    "  - named_entities (each with name and job)  \n",
    "  - april_events (list of event summaries with date, description) e.g Any year above 2006 is false because the information is before 2006\n",
    "\n",
    "\n",
    "Analyze the following text and provide your response:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6cd5b570-0c1f-4d83-954a-3e93f2fce18b",
   "metadata": {},
   "source": [
    "system_content = \"\"\"\n",
    "You are an AI assistant designed to analyze text data and classify it according to specific categories related to business, sports, and entertainment.  \n",
    "Your role is to extract structured information that helps categorize the content quickly and accurately.\n",
    "\n",
    "Business Context:  \n",
    "- Texts may include news, reports, or summaries involving various subcategories within business, sports, and entertainment.  \n",
    "- You will identify key named entities such as media personalities and their roles or jobs, which may not be limited to a fixed predefined list.  \n",
    "- Your classification must include confidence scores to indicate reliability.\n",
    "\n",
    "Your tasks for each input text are to:  \n",
    "1. Assign the most relevant categories in business, sports, and entertainment (if applicable).  \n",
    "2. Extract named entities with their full names and job descriptions (job can be free text, not limited to a fixed list).  \n",
    "3. Extract **only** the events explicitly stated to occur in **April** (no other months). Return a list of April events with date, title, and description.  \n",
    "4. Provide a confidence score between 0 and 1 for your classification accuracy.\n",
    "\n",
    "Important notes:  \n",
    "- Use free-text for the job type of named entities, allowing for flexibility in new or uncommon job titles.  \n",
    "- Base your analysis solely on the provided text without assumptions.  \n",
    "- If unsure, lower the confidence score accordingly.  \n",
    "- The output should be structured and formatted as JSON matching the following keys:  \n",
    "  - business  \n",
    "  - sports  \n",
    "  - entertainment  \n",
    "  - confidence  \n",
    "  - named_entities (each with name and job)  \n",
    "  - april_events (list of event summaries with date, title, description)\n",
    "\n",
    "April Events Extraction Guidance:\n",
    "\n",
    "- Extract only events clearly linked to April.\n",
    "- Do not fabricate or include events from other months.\n",
    "- Format each event with keys: event_date, title, description.\n",
    "- If no April events, return an empty list.\n",
    "\n",
    "Examples:\n",
    "\n",
    "Example 1 (Input Text):\n",
    "\"The London Marathon is scheduled for April 23. Thousands are expected to participate.\"\n",
    "Output:\n",
    "\"april_events\": [\n",
    "    {\n",
    "        \"event_date\": \"April 23\",\n",
    "        \"title\": \"London Marathon\",\n",
    "        \"description\": \"Thousands are expected to participate.\"\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "Example 2 (Input Text):\n",
    "\"June is the month we expect to see new policies announced by the government.\"\n",
    "Output:\n",
    "\"april_events\": [\n",
    "    {\n",
    "        \"event_date\": \"\",\n",
    "        \"title\": \"\",\n",
    "        \"description\": \"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "Analyze the following text and provide your response:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c34c5f-4387-41fe-8074-32fa7328a19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_content =  \"\"\"\n",
    "You are an AI assistant designed to analyze text data and classify it according to specific categories related to business, sports, and entertainment.  \n",
    "Your role is to extract structured information that helps categorize the content quickly and accurately.\n",
    "\n",
    "Business Context:  \n",
    "- Texts may include news, reports, or summaries involving various subcategories within business, sports, and entertainment.  \n",
    "- You will identify key named entities such as media personalities and their roles or jobs, which may not be limited to a fixed predefined list.  \n",
    "- Your classification must include confidence scores to indicate reliability.\n",
    "\n",
    "Your tasks for each input text are to:  \n",
    "1. Assign the most relevant categories in business, sports, and entertainment (if applicable).  \n",
    "2. Extract named entities with their full names and job descriptions (job can be free text, not limited to a fixed list).  \n",
    "3. **APRIL EVENTS - HIGH RECALL**: Extract ANY events that could occur in April (any year before 2006). Include events with explicit \"April\" mentions OR spring/seasonal references that could indicate April timing. When uncertain about April timing, INCLUDE with lower confidence rather than exclude.\n",
    "4. Provide a confidence score between 0 and 1 for your classification accuracy.\n",
    "\n",
    "Important notes:  \n",
    "- Use free-text for the job type of named entities, allowing for flexibility in new or uncommon job titles.  \n",
    "- Base your analysis solely on the provided text without assumptions.  \n",
    "- For April events: Maximum recall approach - if there's ANY possibility it could be April, include it.\n",
    "- If unsure, lower the confidence score accordingly.  \n",
    "- The output should be structured and formatted as JSON matching the following keys:  \n",
    "  - business  \n",
    "  - sports  \n",
    "  - entertainment  \n",
    "  - confidence  \n",
    "  - named_entities (each with name and job)  \n",
    "  - april_events (list of event summaries with date, description)\n",
    "\n",
    "Analyze the following text and provide your response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a94cedf-b246-485c-adf6-477b61aeb161",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=\"gpt-4o\"\n",
    "root_dir = \"bbc\"   # Change this to directory of the folders where the categories are saved\n",
    "t = f'gpt3.5_turbo_result.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d035dc58-3668-4893-804d-1019b17274b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Running all the process\n",
      "Continue with Trained_df\n",
      "Model already trained. Loading the data from gpt3.5_turbo_result.csv\n",
      "Load Trained Model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>classes</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>business</th>\n",
       "      <th>sports</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>confidence</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>april_events</th>\n",
       "      <th>contains_april</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>true_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Ad sales boost Time Warner profit Quarterly pr...</td>\n",
       "      <td>business</td>\n",
       "      <td>1407</td>\n",
       "      <td>421</td>\n",
       "      <td>company_news</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'name': 'Richard Parsons', 'job': 'Chairman ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dollar gains on Greenspan speech The dollar ha...</td>\n",
       "      <td>business</td>\n",
       "      <td>1407</td>\n",
       "      <td>384</td>\n",
       "      <td>economy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'name': 'Alan Greenspan', 'job': 'Federal Re...</td>\n",
       "      <td>[]</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Yukos unit buyer faces loan claim The owners o...</td>\n",
       "      <td>business</td>\n",
       "      <td>1407</td>\n",
       "      <td>264</td>\n",
       "      <td>energy_oil_gas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'name': 'Menatep Group', 'job': 'Owner'}, {'...</td>\n",
       "      <td>[{'event_date': 'April', 'title': 'Yukos Unit ...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text   classes  \\\n",
       "0           0  Ad sales boost Time Warner profit Quarterly pr...  business   \n",
       "1           1  Dollar gains on Greenspan speech The dollar ha...  business   \n",
       "2           2  Yukos unit buyer faces loan claim The owners o...  business   \n",
       "\n",
       "   char_counts  word_counts        business sports entertainment  confidence  \\\n",
       "0         1407          421    company_news    NaN           NaN         0.9   \n",
       "1         1407          384         economy    NaN           NaN         0.9   \n",
       "2         1407          264  energy_oil_gas    NaN           NaN         0.9   \n",
       "\n",
       "                                      named_entities  \\\n",
       "0  [{'name': 'Richard Parsons', 'job': 'Chairman ...   \n",
       "1  [{'name': 'Alan Greenspan', 'job': 'Federal Re...   \n",
       "2  [{'name': 'Menatep Group', 'job': 'Owner'}, {'...   \n",
       "\n",
       "                                        april_events  contains_april  \\\n",
       "0                                                 []           False   \n",
       "1                                                 []           False   \n",
       "2  [{'event_date': 'April', 'title': 'Yukos Unit ...           False   \n",
       "\n",
       "   pred_label  true_label  \n",
       "0           0           0  \n",
       "1           0           0  \n",
       "2           1           0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained Model Loaded Complete\n",
      "Start Saving sub categories into new folders\n",
      "End Saving sub categories into new folders\n",
      "\n",
      "\n",
      "===================================================================================================================================================================\n",
      "Start Saving April Occurences into April Folder\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'nos'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\llms\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'nos'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m bbc = BBC(root_dir, system_content, model, trained_df=t, train=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbbc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\llm\\llm_engineering\\bbc-fulltext\\bbc.py:330\u001b[39m, in \u001b[36mBBC.process\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    328\u001b[39m \u001b[38;5;28mself\u001b[39m.run_model()\n\u001b[32m    329\u001b[39m \u001b[38;5;28mself\u001b[39m.save_subcategories()\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msave_april\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28mself\u001b[39m.save_name_job_entities()\n\u001b[32m    332\u001b[39m \u001b[38;5;28mself\u001b[39m.analysis()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Desktop\\llm\\llm_engineering\\bbc-fulltext\\bbc.py:258\u001b[39m, in \u001b[36mBBC.save_april\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    254\u001b[39m os.makedirs(april_folder, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m filtered_dfs.iterrows():\n\u001b[32m    257\u001b[39m     \u001b[38;5;66;03m# Use nos if valid, else fallback to index; add idx to ensure uniqueness\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m     nos_val = \u001b[38;5;28mstr\u001b[39m(row[\u001b[33m'\u001b[39m\u001b[33mnos\u001b[39m\u001b[33m'\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m pd.notna(\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnos\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mmissing\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    259\u001b[39m     file_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnos_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m     file_path = os.path.join(april_folder, file_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\llms\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[39m, in \u001b[36mSeries.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[key]\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1123\u001b[39m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[32m   1124\u001b[39m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[32m   1125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\llms\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[39m, in \u001b[36mSeries._get_value\u001b[39m\u001b[34m(self, label, takeable)\u001b[39m\n\u001b[32m   1234\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[label]\n\u001b[32m   1236\u001b[39m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1237\u001b[39m loc = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[32m   1240\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._values[loc]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\llms\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'nos'"
     ]
    }
   ],
   "source": [
    "bbc = BBC(root_dir, system_content, model, trained_df, train=True)\n",
    "bbc.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df832e17-346c-4678-85c5-d70d52a8387f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
